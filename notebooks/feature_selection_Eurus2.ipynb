{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import  train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as opt_lgb\n",
    "from sklearn.metrics import log_loss, f1_score, matthews_corrcoef, roc_auc_score, confusion_matrix, brier_score_loss\n",
    "import argparse\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import optuna\n",
    "import json\n",
    "import gc\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_helper#\n",
    "\n",
    "def read_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    cat_features = list(data.select_dtypes(include=['object']).columns)\n",
    "    data[cat_features] = data[cat_features].astype(\"category\") \n",
    "    return data\n",
    "\n",
    "def balanced_train_validation_test(data, target_column,random_state):\n",
    "    X = data.loc[:, data.columns != target_column]\n",
    "    y = data[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def fundtap_train_test_split(data,target_column = \"label\",\n",
    "                     hold_out_columns = [\"quote\",\"fundtap_profit_loss\"],\n",
    "                    random_state = 456):\n",
    "    \n",
    "    categorical_feature = list(data.select_dtypes(include=['object']).columns)\n",
    "    data[categorical_feature] = data[categorical_feature].astype(\"category\")\n",
    "    X_train, X_test, y_train, y_test = balanced_train_validation_test(data.loc[:, ~data.columns.isin(hold_out_columns)],target_column,random_state)\n",
    "    \n",
    "    train_instance_weight = np.abs(data.loc[X_train.index][\"fundtap_profit_loss\"])\n",
    "    test_instance_weight = np.abs(data.loc[X_test.index][\"fundtap_profit_loss\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18741\\AppData\\Local\\Temp\\ipykernel_24284\\1291651966.py:7: DtypeWarning: Columns (7,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('../data/train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Function to clean column names #\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "    return df\n",
    "\n",
    "# Assuming processed_data is a DataFrame\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "processed_data = clean_column_names(train_data)\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "processed_data_path = '../data/processed_data.csv'\n",
    "processed_data.to_csv(processed_data_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6863, 142)\n",
      "X_test shape: (1716, 142)\n",
      "y_train shape: (6863,)\n",
      "y_test shape: (1716,)\n",
      "Train instance weight shape: (6863, 2)\n",
      "Test instance weight shape: (1716, 2)\n",
      "Number of columns used for training: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18741\\AppData\\Local\\Temp\\ipykernel_24284\\4076922104.py:4: DtypeWarning: Columns (7,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "train_data_path = '../data/train.csv'\n",
    "dictionary_path = '../data/fundtap-data-dictionary.csv'\n",
    "\n",
    "train_data = read_data(train_data_path)\n",
    "processed_data = clean_column_names(train_data)\n",
    "processed_data[\"label\"] = processed_data.fundtap_profit_loss >= 0\n",
    "\n",
    "# Load data dictionary and select features for training\n",
    "data_dictionary = pd.read_csv(dictionary_path)\n",
    "columns_for_training = data_dictionary[data_dictionary[\"use_for_training\"] == \"Y\"][\"columns_cleaned\"].tolist()\n",
    "\n",
    "# Add label column to the selected columns\n",
    "selected_columns = columns_for_training + [\"label\", \"fundtap_profit_loss\", \"quote\"]\n",
    "df = processed_data[selected_columns]\n",
    "\n",
    "# Run the training function\n",
    "X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight = fundtap_train_test_split(\n",
    "    df, \n",
    "    target_column=\"label\",\n",
    "    hold_out_columns=[\"quote\", \"fundtap_profit_loss\"],\n",
    "    random_state=456\n",
    ")\n",
    "\n",
    "# Output shapes of the splits and weights\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"Train instance weight shape:\", train_instance_weight.shape)\n",
    "print(\"Test instance weight shape:\", test_instance_weight.shape)\n",
    "print(\"Number of columns used for training:\", len(columns_for_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Eurus,\n",
    "如上文：X_train 里现在有151个columns，y_train 里有1个colums. 所以参与模型training的columns一共有151+1=152个。\n",
    "现在fundtap-data-dictionary（索引）里要求的use for training的columns一共却只有144个。\n",
    "接下来你和gpt的任务，就是让实际参与模型training的columns数量 = use for training的columns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
