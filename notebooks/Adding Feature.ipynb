{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import  train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as opt_lgb\n",
    "from sklearn.metrics import log_loss, f1_score, matthews_corrcoef, roc_auc_score, confusion_matrix, brier_score_loss\n",
    "import argparse\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import optuna\n",
    "import json\n",
    "import gc\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_helper#\n",
    "\n",
    "def load_dictionary(dictionary_path):\n",
    "    data_dictionary = pd.read_csv(dictionary_path)\n",
    "    training_columns = data_dictionary[data_dictionary[\"use_for_training\"] == \"Y\"][\"columns_cleaned\"].tolist()\n",
    "    hold_out_columns = data_dictionary[data_dictionary[\"hold_out_columns\"] == \"Y\"][\"columns_cleaned\"].tolist()\n",
    "    return training_columns, hold_out_columns\n",
    "\n",
    "def select_data(data, dictionary_path, target_column):\n",
    "    # Get the columns to use for training and the columns to hold out\n",
    "    training_columns, hold_out_columns = load_dictionary(dictionary_path)\n",
    "\n",
    "    # Ensure only training columns are used, excluding hold-out columns and the target column\n",
    "    training_columns = [col for col in training_columns if col not in hold_out_columns + [target_column]]\n",
    "    \n",
    "    # Filter data to include only training columns plus the target column\n",
    "    data = data[training_columns+ [target_column]]\n",
    "\n",
    "    # Define catgorical features #\n",
    "    cat_features = list(data.select_dtypes(include=['object']).columns)\n",
    "    data[cat_features] = data[cat_features].astype(\"category\") \n",
    "    return data\n",
    "\n",
    "def balanced_train_validation_test(data, target_column,random_state):\n",
    "    X = data.loc[:, data.columns != target_column]\n",
    "    y = data[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def fundtap_train_test_split(data, dictionary_path, target_column=\"label\",random_state=456):            \n",
    "    data = select_data(data, dictionary_path, target_column)\n",
    "    X_train, X_test, y_train, y_test = balanced_train_validation_test(data, target_column, random_state)\n",
    "    \n",
    "    train_instance_weight = np.abs(data.loc[X_train.index][\"fundtap_profit_loss\"])\n",
    "    test_instance_weight = np.abs(data.loc[X_test.index][\"fundtap_profit_loss\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hp_tuning_helper#\n",
    "\n",
    "def learning_rate_decay_power_0995(current_iter): \n",
    "    base_learning_rate = 0.1 \n",
    "    lr = base_learning_rate * np.power(.995, current_iter) \n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "\n",
    "def hp_tuning_init_param(X_train, y_train, metric, k_folds, feval,random_state):\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING) \n",
    "    dtrain = opt_lgb.Dataset(X_train, label=y_train)\n",
    "    \n",
    "    fixed_param =  params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": metric,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'random_state' : random_state,\n",
    "        'verbose':-1,\n",
    "        'is_unbalance': 'true'\n",
    "    }\n",
    "\n",
    "    tuner = opt_lgb.LightGBMTunerCV(\n",
    "        fixed_param, dtrain, verbose_eval=False,\n",
    "        early_stopping_rounds=100, \n",
    "        nfold = k_folds,\n",
    "        stratified = True,\n",
    "        show_progress_bar = False,\n",
    "        optuna_seed = random_state,\n",
    "        feval=feval,\n",
    "        callbacks=[lgb.reset_parameter(learning_rate = learning_rate_decay_power_0995) ]\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    tuner.run()\n",
    "    return tuner.best_params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_interpretation_helper#\n",
    "\n",
    "def accuracy_analysis(classifier, X_train, X_test, y_train, y_test, test_instance_weight ):\n",
    "\n",
    "        pred_proba = classifier.predict(X_test)\n",
    "        yhat =np.where(pred_proba < 0.5, 0, 1) \n",
    "\n",
    "        mcc = matthews_corrcoef(y_test, yhat)\n",
    "        logloss = log_loss(y_test, pred_proba)\n",
    "        bs= brier_score_loss(y_test, pred_proba)\n",
    "\n",
    "\n",
    "        weighted_mcc = matthews_corrcoef(y_test, yhat, sample_weight = test_instance_weight)\n",
    "        weighted_logloss = log_loss(y_test, pred_proba,sample_weight=test_instance_weight)\n",
    "        weighted_bs= brier_score_loss(y_test, pred_proba, sample_weight= test_instance_weight)\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, yhat).ravel()\n",
    "        fpr = (fp)/ float(fp + tn)\n",
    "        fnr = (fn)/ float(fn + tp)\n",
    "        train_tn, train_fp, train_fn, train_tp = confusion_matrix(y_train, np.where(classifier.predict(X_train) < 0.5, 0, 1) ).ravel()\n",
    "        train_fpr = (train_fp)/ float(train_fp + train_tn)\n",
    "        train_fnr = (train_fn)/ float(train_fn + train_tp)\n",
    "\n",
    "        accuracy_df = pd.DataFrame([  weighted_mcc, weighted_logloss, weighted_bs, mcc, logloss, bs, tn, fp, fn, tp, fpr, fnr, train_tn, train_fp, train_fn, train_tp,train_fpr,train_fnr])\n",
    "        accuracy_df = accuracy_df.transpose()\n",
    "        accuracy_df.columns = [ \"weighted_mcc\", \"weighted_logloss\", \"weighted_bs\", \"mcc\", \"logloss\", \"brier_score_loss\", \"tn\", \"fp\", \"fn\", \"tp\", \"fpr\", \"fnr\", \"train_tn\", 'train_fp', \"train_fn\", \"train_tp\",\"train_fpr\",\"train_fnr\"]\n",
    "        if test_instance_weight.unique().size > 1:\n",
    "                total_loss = test_instance_weight[yhat!=y_test].sum()\n",
    "                fp_loss = test_instance_weight[(yhat!=y_test) & (yhat==1) ].sum()\n",
    "                fn_loss = test_instance_weight[(yhat!=y_test) & (yhat == 0)].sum()\n",
    "                accuracy_df[\"total_loss\"] = total_loss\n",
    "                accuracy_df[\"fp_loss\"] = fp_loss\n",
    "                accuracy_df[\"fn_loss\"] = fn_loss\n",
    "        return accuracy_df\n",
    "\n",
    "\n",
    "def multiclass_accuracy_analysis(classifier, X_test, y_test ):\n",
    "        pred_proba = classifier.predict(X_test)\n",
    "        yhat = list(pred_proba.argmax(axis = 1))\n",
    "        return pd.DataFrame(confusion_matrix(y_test, yhat))\n",
    "\n",
    "\n",
    "    \n",
    "def get_feature_importance(classifier):\n",
    "        feature_importance = pd.DataFrame({'Features': classifier.feature_name(),'Importances': classifier.feature_importances()})\n",
    "        feature_importance.sort_values(by='Importances', inplace=True,ascending = False )\n",
    "        return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training#\n",
    "\"\"\"\n",
    "TRAINING FUNCTIONS: this file in run in 'script mode' when `.fit` is called\n",
    "from the notebook. `parse_args` and `train_fn` are called in the\n",
    "`if __name__ =='__main__'` block.\n",
    "\"\"\"\n",
    "shap.initjs()\n",
    "\n",
    "\n",
    "NUMERICAL_TYPES = set([\"boolean\", \"integer\", \"number\"])\n",
    "CATEGORICAL_TYPES = set([\"string\"])\n",
    "\n",
    "\n",
    "class AsTypeFloat32(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.astype(\"float32\")\n",
    "\n",
    "\n",
    "def get_numerical_idxs(data_schema):\n",
    "    idxs = get_idxs(data_schema, NUMERICAL_TYPES)\n",
    "    return idxs\n",
    "\n",
    "\n",
    "def get_categorical_idxs(data_schema):\n",
    "    idxs = get_idxs(data_schema, CATEGORICAL_TYPES)\n",
    "    return idxs\n",
    "\n",
    "\n",
    "def get_idxs(data_schema, types):\n",
    "    idxs = []\n",
    "    for idx, type in enumerate(data_schema.item_types):\n",
    "        if type in types:\n",
    "            idxs.append(idx)\n",
    "    return idxs\n",
    "\n",
    "\n",
    "def create_preprocessor(data_schema) -> ColumnTransformer:\n",
    "    numerical_idxs = get_numerical_idxs(data_schema)\n",
    "    numerical_transformer = AsTypeFloat32()\n",
    "    categorical_idxs = get_categorical_idxs(data_schema)\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numerical\", numerical_transformer, numerical_idxs),\n",
    "            (\"categorical\", categorical_transformer, categorical_idxs),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def preprocess_numerical_schema(preprocessor, data_schema):\n",
    "    num_idx = [e[0] for e in preprocessor.transformers].index(\"numerical\")\n",
    "    numerical_idxs = get_numerical_idxs(data_schema)\n",
    "    numerical_items = [data_schema.items[idx] for idx in numerical_idxs]\n",
    "    features = []\n",
    "    for item in numerical_items:\n",
    "        feature = {\n",
    "            \"title\": item[\"title\"],\n",
    "            \"description\": item[\"description\"],\n",
    "            \"type\": \"number\"\n",
    "        }\n",
    "        features.append(feature)\n",
    "    return num_idx, features\n",
    "\n",
    "\n",
    "def preprocess_categorical_schema(preprocessor, data_schema):\n",
    "    cat_idx = [e[0] for e in preprocessor.transformers].index(\"categorical\")\n",
    "    categorical_idxs = get_categorical_idxs(data_schema)\n",
    "    categorical_items = [data_schema.items[idx] for idx in categorical_idxs]\n",
    "    features = []\n",
    "    ohe = preprocessor.transformers_[cat_idx][1]\n",
    "    for item, categories in zip(categorical_items, ohe.categories_):\n",
    "        for category in categories:\n",
    "            feature = {\n",
    "                \"title\": \"{}__{}\".format(item[\"title\"], category),\n",
    "                \"description\": \"{} is '{}' if value is 1.0.\".format(\n",
    "                    item[\"description\"].strip('.'), category\n",
    "                ),\n",
    "                \"type\": \"number\"\n",
    "            }\n",
    "            features.append(feature)\n",
    "    return cat_idx, features\n",
    "\n",
    "\n",
    "def transform_schema(preprocessor, data_schema):\n",
    "    num_idx, num_features = preprocess_numerical_schema(preprocessor, data_schema)  # noqa\n",
    "    cat_idx, cat_features = preprocess_categorical_schema(preprocessor, data_schema)  # noqa\n",
    "    assert num_idx < cat_idx, \"Ordering should be numerical, then categorical.\"\n",
    "    features = num_features + cat_features\n",
    "\n",
    "    array_schema = {\n",
    "        \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n",
    "        \"type\": \"array\",\n",
    "        \"minItems\": len(features),\n",
    "        \"maxItems\": len(features),\n",
    "        \"items\": features,\n",
    "        \"title\": data_schema.title,\n",
    "        \"description\": data_schema.description.replace(\n",
    "            \"items\", \"features\"\n",
    "        ),\n",
    "    }\n",
    "    return schemas.Schema(array_schema)\n",
    "\n",
    "\n",
    "def load_schemas(schemas_folder):\n",
    "    data_schema_filepath = Path(schemas_folder, \"data.schema.json\")\n",
    "    data_schema = schemas.from_json_schema(data_schema_filepath)\n",
    "    label_schema_filepath = Path(schemas_folder, \"label.schema.json\")\n",
    "    label_schema = schemas.from_json_schema(label_schema_filepath)\n",
    "    return data_schema, label_schema\n",
    "\n",
    "\n",
    "def log_cross_val_auc(clf, X, y, cv_splits, log_prefix):\n",
    "    cv_auc = cross_val_score(clf, X, y, cv=cv_splits, scoring='roc_auc')\n",
    "    cv_auc_mean = cv_auc.mean()\n",
    "    cv_auc_error = cv_auc.std() * 2\n",
    "    log = \"{}_auc_cv: {:.5f} (+/- {:.5f})\"\n",
    "    print(log.format(log_prefix, cv_auc_mean, cv_auc_error))\n",
    "\n",
    "\n",
    "def log_auc(clf, X, y, log_prefix):\n",
    "    y_pred_proba = clf.predict_proba(X)\n",
    "    auc = roc_auc_score(y, y_pred_proba[:, 1])\n",
    "    log = '{}_auc: {:.5f}'\n",
    "    print(log.format(log_prefix, auc))\n",
    "\n",
    "\n",
    "def train_pipeline(pipeline, X, y, cv_splits):\n",
    "    # fit pipeline to cross validation splits\n",
    "    if cv_splits > 1:\n",
    "        log_cross_val_auc(pipeline, X, y, cv_splits, 'train')\n",
    "    # fit pipeline to all training data\n",
    "    pipeline.fit(X, y)\n",
    "    log_auc(pipeline, X, y, 'train')\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def test_pipeline(pipeline, X, y):\n",
    "    log_auc(pipeline, X, y, 'test')\n",
    "\n",
    "\n",
    "def parse_args(sys_args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--tree-boosting-type\",\n",
    "        type=str,\n",
    "        default=\"gbdt\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cv-splits\",\n",
    "        type=int,\n",
    "        default=5\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model-dir\",\n",
    "        type=str,\n",
    "        default=os.environ.get(\"SM_MODEL_DIR\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--schemas\",\n",
    "        type=str,\n",
    "        default=os.environ.get(\"SM_CHANNEL_SCHEMAS\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data-train\",\n",
    "        type=str,\n",
    "        default=os.environ.get(\"SM_CHANNEL_DATA_TRAIN\"),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--hyperparameters\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--label-train\",\n",
    "        type=str,\n",
    "        default=os.environ.get(\"SM_CHANNEL_LABEL_TRAIN\"),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data-test\",\n",
    "        type=str,\n",
    "        default=os.environ.get(\"SM_CHANNEL_DATA_TEST\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--label-test\",\n",
    "        type=str,\n",
    "        default=os.environ.get(\"SM_CHANNEL_LABEL_TEST\"),\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--ramdom-state\",\n",
    "        type=str,\n",
    "        default=456,\n",
    "    )\n",
    "\n",
    "    args, _ = parser.parse_known_args(sys_args)\n",
    "    return args\n",
    "\n",
    "def get_shap_values(X_train, X_test, final_clf, model_dir, file_prefix):\n",
    "    # Identify categorical columns\n",
    "    cat_cols = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "    \n",
    "    # Ensure both train and test datasets have the same categories\n",
    "    for col in cat_cols:\n",
    "        combined = pd.concat([X_train[col], X_test[col]], axis=0).astype('category')\n",
    "        X_train[col] = X_train[col].astype('category').cat.set_categories(combined.cat.categories)\n",
    "        X_test[col] = X_test[col].astype('category').cat.set_categories(combined.cat.categories)\n",
    "    \n",
    "    # Convert all features to numeric\n",
    "    X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "    X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Fill NaN values with 0 or you can use another strategy\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "\n",
    "    # Combine train and test datasets\n",
    "    X = pd.concat([X_train, X_test])\n",
    "\n",
    "    explainer = shap.TreeExplainer(final_clf, feature_perturbation='interventional')\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    print(f\"Type of shap_values: {type(shap_values)}\")\n",
    "    print(f\"Shape of shap_values: {shap_values.shape if isinstance(shap_values, np.ndarray) else [v.shape for v in shap_values]}\")\n",
    "\n",
    "    if isinstance(shap_values, list):  # Check if shap_values is a list (multi-class classification)\n",
    "        shap_values = shap_values[1]  # Use the shap values for class 1 for binary classification\n",
    "    shap_values = np.array(shap_values) if shap_values.ndim == 1 else shap_values\n",
    "    print(f\"Shape of shap_values after conversion: {shap_values.shape}\")\n",
    "\n",
    "    vals = np.abs(np.array(shap_values)).mean(axis=0)\n",
    "    print(f\"Shape of vals: {vals.shape}\")\n",
    "\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    feature_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                      columns=['col_name', 'feature_importance_vals'])\n",
    "    feature_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "    shap.summary_plot(shap_values, X, max_display=40, show=False)\n",
    "    plt.savefig(Path(model_dir, file_prefix + \".png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    X.to_csv(Path(model_dir, file_prefix + \"X.csv\"))\n",
    "    for name in list(feature_importance.col_name)[0:30]:\n",
    "        shap.dependence_plot(name, shap_values, X, display_features=X, show=False)\n",
    "        plt.savefig(Path(model_dir, file_prefix + \"_\" + name + \".png\"), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def train_profit_loss_binary(df, dictionary_path, hyperparameters, model_dir, new_customer):\n",
    "    ## load data\n",
    "    df[\"label\"] = df.fundtap_profit_loss >= 0\n",
    "    \n",
    "    # create components\n",
    "    warm_starting_param = \"\"\n",
    "    if hyperparameters != \"\":\n",
    "        warm_starting_param = datasets.read_hyper_parameters(hyperparameters)\n",
    "    else:\n",
    "        warm_starting_param = {\"bagging_fraction\": 0.5492535456145099, \"bagging_freq\": 2, \"feature_fraction\": 0.88, \"lambda_l1\": 0.00011548574578690704, \"lambda_l2\": 1.3199945533897172e-06, \"max_depth\": 12, \"min_child_samples\": 10, \"num_leaves\": 48}\n",
    "    random_state = 456   \n",
    "    fixed_param = {\n",
    "    'objective': 'binary',\n",
    "    'metric':  \"binary_logloss\",\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': random_state,\n",
    "    'verbose': -1,\n",
    "    'feature_pre_filter': False\n",
    "    }\n",
    "\n",
    "    if new_customer:\n",
    "        columns_to_drop = [\"funded_outstanding\",\"priorfundtaphistoryfundedsum\",\"priorfundtaphistorycompletedsum\", \"priorfundtaphistoryduesum\", \"priorfundtaphistorypendingsum\"]\n",
    "        df = df.drop(columns = columns_to_drop, errors = 'ignore')\n",
    "    # full-model \n",
    "    X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight = fundtap_train_test_split(df, dictionary_path, target_column=\"label\", random_state=456)\n",
    "    weight = train_instance_weight\n",
    "    def objective(trial):\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 14)\n",
    "        max_num_leaves = (2 ** max_depth) - 1\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train, weight=weight)\n",
    "        param = {\n",
    "            'objective': 'binary',\n",
    "            'metric': \"binary_logloss\",\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'max_depth': max_depth,\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, max_num_leaves),\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0,log=True),\n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0,log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 0, 15),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "            'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-3, 10),\n",
    "            'seed': random_state\n",
    "        }\n",
    "\n",
    "        lgbcv = lgb.cv(param,\n",
    "                    dtrain,\n",
    "                    nfold=5,\n",
    "                    stratified=True,\n",
    "                    num_boost_round=10000,\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(100),\n",
    "                        lgb.reset_parameter(learning_rate=learning_rate_decay_power_0995)\n",
    "                    ]\n",
    "                    )\n",
    "        print(\"CV Results Keys:\", lgbcv.keys())  # Debugging: Print the keys of the CV results\n",
    "    \n",
    "        score_mean = \"binary_logloss-mean\"\n",
    "        score_stdv = \"binary_logloss-stdv\"\n",
    "\n",
    "        if score_mean in lgbcv and score_stdv in lgbcv:\n",
    "            cv_score = lgbcv[score_mean][-1] + lgbcv[score_stdv][-1]\n",
    "        else:\n",
    "            print(f\"Keys {score_mean} and {score_stdv} not found in CV results.\")\n",
    "            cv_score = float('inf')  # Assign a large value to ensure this trial is not selected\n",
    "\n",
    "        return cv_score\n",
    "       \n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\")  # default TPE sampleR\n",
    "    study.enqueue_trial({**fixed_param, **warm_starting_param})\n",
    "    n_trials = 10\n",
    "    study.optimize(objective, n_trials=n_trials, gc_after_trial=True, n_jobs = 3)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train, weight=weight)\n",
    "    classifier = lgb.train({**fixed_param, **best_params}, dtrain)\n",
    "    accuracy = accuracy_analysis(\n",
    "        classifier, X_train, X_test, y_train, y_test, test_instance_weight)\n",
    "\n",
    "    # save components\n",
    "    final_dtrain = lgb.Dataset(pd.concat([X_train, X_test]), label=pd.concat([y_train, y_test]), weight=pd.concat([train_instance_weight, test_instance_weight]))\n",
    "    final_clf = lgb.train({**fixed_param, **best_params}, final_dtrain)\n",
    "\n",
    "    model_dir = Path(model_dir)\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "    if new_customer:\n",
    "        file_prefix = \"new_customer_profitloss\"\n",
    "    else:\n",
    "        file_prefix = \"existing_customer_profitloss\"\n",
    "    joblib.dump(final_clf, Path(model_dir, file_prefix+\"classifier.joblib\"))\n",
    "    accuracy.to_csv(Path(model_dir, file_prefix+\"accuracy.csv\"))\n",
    "    with open(Path(model_dir, file_prefix+\"hyperparamter.json\"), 'w') as fp:\n",
    "        json.dump({**best_params}, fp)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def train_profit_loss_multi(train_data_path, hyperparameters,model_dir, new_customer):\n",
    "    ## load data\n",
    "    def encoding_label(x):\n",
    "        if x <4:\n",
    "            return x\n",
    "        else:\n",
    "            return 4\n",
    "    \n",
    "    df = datasets.read_csv_dataset(train_data_path)\n",
    "\n",
    "    df = df[df.fundtap_profit_loss.notnull() & df.fundtap_profit_loss != 0]\n",
    "    df = preprocessing(df, method=\"multi\")\n",
    "    if \"weekspastdue\" not in df.columns:\n",
    "        return 1\n",
    "    df[\"label\"] = df.weekspastdue\n",
    "    df['label'] = df['label'].apply(lambda x: encoding_label(x))\n",
    "\n",
    "    # create components\n",
    "    warm_starting_param = \"\"\n",
    "    if hyperparameters != \"\":\n",
    "        warm_starting_param = datasets.read_hyper_parameters(hyperparameters)\n",
    "    else:\n",
    "        warm_starting_param = {'max_depth': 14,\n",
    "                                'num_leaves': 3445,\n",
    "                                'lambda_l1': 0.0024719526504884707,\n",
    "                                'lambda_l2': 8.956806049714798e-06,\n",
    "                                'feature_fraction': 0.15930975035202272,\n",
    "                                'bagging_fraction': 0.24596777131151706,\n",
    "                                'bagging_freq': 0,\n",
    "                                'min_child_samples': 49,\n",
    "                                'min_sum_hessian_in_leaf': 1.5433498652572106}\n",
    "                                    \n",
    "    random_state = 456   \n",
    "    fixed_param = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric':  \"multi_logloss\",\n",
    "    'num_classes': 5,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': random_state,\n",
    "    'verbose': -1,\n",
    "    'feature_pre_filter': False\n",
    "    }\n",
    "\n",
    "    if new_customer:\n",
    "        columns_to_drop = [\"funded_outstanding\",\"priorfundtaphistoryfundedsum\",\"priorfundtaphistorycompletedsum\", \"priorfundtaphistoryduesum\", \"priorfundtaphistorypendingsum\"]\n",
    "        df = df.drop(columns = columns_to_drop, errors = 'ignore')\n",
    "    # full-model \n",
    "    X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight = fundtap_train_test_split(df, hold_out_columns=[\"quote\",\"fundtap_profit_loss\",\"weekspastdue\"] , random_state = random_state)\n",
    "    weight = train_instance_weight\n",
    "    def objective(trial):\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 14)\n",
    "        max_num_leaves = (2 ** max_depth) - 1\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train, weight=weight)\n",
    "        param = {\n",
    "            'objective': 'multiclass',\n",
    "            'metric': \"multi_logloss\",\n",
    "            'num_classes': 5,\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'max_depth': max_depth,\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, max_num_leaves),\n",
    "            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "            'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 0, 15),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "            'min_sum_hessian_in_leaf': trial.suggest_uniform('min_sum_hessian_in_leaf', 1e-3, 10),\n",
    "            'seed': random_state\n",
    "        }\n",
    "\n",
    "        lgbcv = lgb.cv(param,\n",
    "                    dtrain,\n",
    "                    nfold=3,\n",
    "                    stratified=True,\n",
    "                    verbose_eval=False,\n",
    "                    early_stopping_rounds=100,\n",
    "                    num_boost_round=10000,\n",
    "                    callbacks=[lgb.reset_parameter(\n",
    "                        learning_rate=learning_rate_decay_power_0995)]\n",
    "                    )\n",
    "        score_mean = \"multi_logloss-mean\"\n",
    "        score_stdv = \"multi_logloss-stdv\"\n",
    "        cv_score = lgbcv[score_mean][-1] + lgbcv[score_stdv][-1]\n",
    "        return cv_score\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\")  # default TPE sampleR\n",
    "    study.enqueue_trial({**fixed_param, **warm_starting_param})\n",
    "    n_trials = 10\n",
    "    study.optimize(objective, n_trials=n_trials, gc_after_trial=True, n_jobs = 3)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train, weight=weight)\n",
    "    classifier = lgb.train({**fixed_param, **best_params}, dtrain)\n",
    "    accuracy = multiclass_accuracy_analysis(classifier, X_test, y_test )\n",
    "    # save components\n",
    "    final_dtrain = lgb.Dataset(pd.concat([X_train, X_test]), label=pd.concat([y_train, y_test]), weight=pd.concat([train_instance_weight, test_instance_weight]))\n",
    "    final_clf = lgb.train({**fixed_param, **best_params}, final_dtrain)\n",
    "\n",
    "    \n",
    "    model_dir = Path(model_dir)\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "    if new_customer:\n",
    "        file_prefix = \"new_customer_overdue\"\n",
    "    else:\n",
    "        file_prefix = \"existing_customer_overdue\"\n",
    "    joblib.dump(final_clf, Path(model_dir, file_prefix+\"classifier.joblib\"))\n",
    "    accuracy.to_csv(Path(model_dir, file_prefix+\"accuracy.csv\"))\n",
    "    with open(Path(model_dir, file_prefix+\"hyperparamter.json\"), 'w') as fp:\n",
    "        json.dump({**best_params}, fp)\n",
    "    get_shap_values(X_train,X_test,final_clf,model_dir,file_prefix)\n",
    "\n",
    "def train_fn(args):\n",
    "    train_profit_loss_binary(args.data_train, args.hyperparameters,args.model_dir, new_customer = True)\n",
    "    gc.collect()\n",
    "    train_profit_loss_binary(args.data_train, args.hyperparameters,args.model_dir, new_customer = False)\n",
    "    gc.collect()\n",
    "    train_profit_loss_multi(args.data_train, args.hyperparameters,args.model_dir, new_customer = True)\n",
    "    gc.collect()\n",
    "    train_profit_loss_multi(args.data_train, args.hyperparameters,args.model_dir, new_customer = False)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean column names #\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "    return df\n",
    "\n",
    "# Assuming processed_data is a DataFrame\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "processed_data = clean_column_names(train_data)\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "processed_data_path = '../data/processed_data.csv'\n",
    "processed_data.to_csv(processed_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection #\n",
    "def select_features(data_path, dictionary_path):\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # Load the data dictionary\n",
    "    data_dictionary = pd.read_csv(dictionary_path)\n",
    "    \n",
    "    # Get columns marked as 'Y' in 'use_for_training'\n",
    "    columns_to_use = data_dictionary[data_dictionary[\"use_for_training\"] == \"Y\"][\"columns_cleaned\"].tolist()\n",
    "    \n",
    "    # Filter the data based on the selected columns\n",
    "    filtered_data = data[columns_to_use]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "data_path = \"../data/processed_data.csv\"  # Adjust to your actual data path\n",
    "dictionary_path = \"../data/fundtap-data-dictionary.csv\"  # Adjust to your actual dictionary path\n",
    "    \n",
    "    # Load and filter the data\n",
    "feature_data = select_features(data_path, dictionary_path)\n",
    "    \n",
    "\n",
    "print(feature_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training script\n",
    "data_path = \"../data/processed_data.csv\"\n",
    "dictionary_path = \"../data/fundtap-data-dictionary.csv\"\n",
    "hyperparameters = \"\"\n",
    "model_dir = Path(r\"C:\\Users\\1\\gitrepo\\FundTapMLOps\\model_output_100\")\n",
    "model_dir.mkdir(exist_ok=True, parents=True)\n",
    "new_customer = True\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(data_path)\n",
    "df[\"label\"] = df.fundtap_profit_loss >= 0  # Ensure the label is created before passing it\n",
    "\n",
    "# Run the training function\n",
    "train_profit_loss_binary(df, dictionary_path, hyperparameters, model_dir, new_customer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/processed_data.csv\"  # Adjust to your actual data path\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Print the column names to verify\n",
    "print(df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
