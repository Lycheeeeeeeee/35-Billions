{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import  train_test_split, cross_val_score\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as opt_lgb\n",
    "from sklearn.metrics import log_loss, f1_score, matthews_corrcoef, roc_auc_score, confusion_matrix, brier_score_loss\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import json\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_helper #\n",
    "\n",
    "## load dictionary\n",
    "def load_dictionary(dictionary_path):\n",
    "    data_dictionary = pd.read_csv(dictionary_path)\n",
    "    columns_for_training = data_dictionary[data_dictionary[\"use_for_training\"] == \"Y\"][\"columns_cleaned\"].tolist()\n",
    "    hold_out_columns = data_dictionary[data_dictionary[\"hold_out_columns\"] == \"Y\"][\"columns_cleaned\"].tolist()\n",
    "    prediction_target = data_dictionary[data_dictionary[\"prediction_target\"] == \"Y\"][\"columns_cleaned\"].tolist()\n",
    "    return columns_for_training, hold_out_columns,prediction_target\n",
    "\n",
    "## select features\n",
    "def select_data(data, dictionary_path):\n",
    "    columns_for_training, hold_out_columns,prediction_target = load_dictionary(dictionary_path)\n",
    "    data[\"label\"] = data[prediction_target] >= 0\n",
    "    target_column = \"label\"\n",
    "    data = data[columns_for_training + [target_column]]\n",
    "\n",
    "    # Define catgorical features #\n",
    "    cat_features = list(data.select_dtypes(include=['object']).columns)\n",
    "    data[cat_features] = data[cat_features].astype(\"category\") \n",
    "    return data, hold_out_columns, target_column\n",
    "\n",
    "## train vs. test split\n",
    "def balanced_train_validation_test(data, target_column,random_state):\n",
    "    X = data.loc[:, data.columns != target_column]\n",
    "    y = data[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "## split function\n",
    "def fundtap_train_test_split(data, dictionary_path,random_state=456):  \n",
    "    data, hold_out_columns,target_column = select_data(data, dictionary_path)\n",
    "    X_train, X_test, y_train, y_test = balanced_train_validation_test(data.loc[:, ~data.columns.isin(hold_out_columns)],\n",
    "                                                                      target_column,random_state)\n",
    "    \n",
    "    train_instance_weight = np.abs(data.loc[X_train.index][\"fundtap_profit_loss\"])\n",
    "    test_instance_weight = np.abs(data.loc[X_test.index][\"fundtap_profit_loss\"])\n",
    "\n",
    "    train_holdout = data.loc[X_train.index, hold_out_columns]\n",
    "    test_holdout = data.loc[X_test.index, hold_out_columns]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight,train_holdout,test_holdout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_tuning_helper #\n",
    "\n",
    "def learning_rate_decay_power_0995(current_iter): \n",
    "    base_learning_rate = 0.1 \n",
    "    lr = base_learning_rate * np.power(.995, current_iter) \n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "\n",
    "def hp_tuning_init_param(X_train, y_train, metric, k_folds, feval,random_state):\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING) \n",
    "    dtrain = opt_lgb.Dataset(X_train, label=y_train)\n",
    "    \n",
    "    fixed_param =  params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": metric,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'random_state' : random_state,\n",
    "        'verbose':-1,\n",
    "        'is_unbalance': 'true'\n",
    "    }\n",
    "\n",
    "    tuner = opt_lgb.LightGBMTunerCV(\n",
    "        fixed_param, dtrain, verbose_eval=False,\n",
    "        early_stopping_rounds=100, \n",
    "        nfold = k_folds,\n",
    "        stratified = True,\n",
    "        show_progress_bar = False,\n",
    "        optuna_seed = random_state,\n",
    "        feval=feval,\n",
    "        callbacks=[lgb.reset_parameter(learning_rate = learning_rate_decay_power_0995) ]\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    tuner.run()\n",
    "    return tuner.best_params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_interpretation_helper #\n",
    "\n",
    "def accuracy_analysis(classifier, X_train, X_test, y_train, y_test, test_instance_weight):\n",
    "    pred_proba = classifier.predict(X_test)\n",
    "    yhat = np.where(pred_proba < 0.5, 0, 1)\n",
    "\n",
    "    # Calculate standard metrics\n",
    "    mcc = matthews_corrcoef(y_test, yhat)\n",
    "    logloss = log_loss(y_test, pred_proba)\n",
    "    bs = brier_score_loss(y_test, pred_proba)\n",
    "\n",
    "    # Calculate weighted metrics\n",
    "    weighted_mcc = matthews_corrcoef(y_test, yhat, sample_weight = test_instance_weight)\n",
    "    weighted_logloss = log_loss(y_test, pred_proba,sample_weight=test_instance_weight)\n",
    "    weighted_bs= brier_score_loss(y_test, pred_proba, sample_weight= test_instance_weight)\n",
    "\n",
    "    # Confusion matrix and rates\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, yhat).ravel()\n",
    "    fpr = (fp) / float(fp + tn)\n",
    "    fnr = (fn) / float(fn + tp)\n",
    "\n",
    "    # Training set confusion matrix and rates\n",
    "    train_yhat = np.where(classifier.predict(X_train) < 0.5, 0, 1)\n",
    "    train_tn, train_fp, train_fn, train_tp = confusion_matrix(y_train, train_yhat).ravel()\n",
    "    train_fpr = (train_fp) / float(train_fp + train_tn)\n",
    "    train_fnr = (train_fn) / float(train_fn + train_tp)\n",
    "\n",
    "    # Create the DataFrame\n",
    "    accuracy_df = pd.DataFrame([weighted_mcc, weighted_logloss, weighted_bs, mcc, logloss, bs, tn, fp, fn, tp, fpr, fnr, train_tn, train_fp, train_fn, train_tp, train_fpr, train_fnr])\n",
    "    accuracy_df = accuracy_df.transpose()\n",
    "    accuracy_df.columns = [\"weighted_mcc\", \"weighted_logloss\", \"weighted_bs\", \"mcc\", \"logloss\", \"brier_score_loss\", \"tn\", \"fp\", \"fn\", \"tp\", \"fpr\", \"fnr\", \"train_tn\", 'train_fp', \"train_fn\", \"train_tp\", \"train_fpr\", \"train_fnr\"]\n",
    "\n",
    "    # Calculate and include total loss, fp loss, and fn loss if test_instance_weight is not uniform\n",
    "    if test_instance_weight.unique().size > 1:\n",
    "        total_loss = test_instance_weight[yhat != y_test].sum()\n",
    "        fp_loss = test_instance_weight[(yhat != y_test) & (yhat == 1)].sum()\n",
    "        fn_loss = test_instance_weight[(yhat != y_test) & (yhat == 0)].sum()\n",
    "        accuracy_df[\"total_loss\"] = total_loss\n",
    "        accuracy_df[\"fp_loss\"] = fp_loss\n",
    "        accuracy_df[\"fn_loss\"] = fn_loss\n",
    "\n",
    "    return accuracy_df\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_accuracy_analysis(classifier, X_test, y_test ):\n",
    "        pred_proba = classifier.predict(X_test)\n",
    "        yhat = list(pred_proba.argmax(axis = 1))\n",
    "        return pd.DataFrame(confusion_matrix(y_test, yhat))\n",
    "\n",
    "\n",
    "    \n",
    "def get_feature_importance(classifier):\n",
    "        feature_importance = pd.DataFrame({'Features': classifier.feature_name(),'Importances': classifier.feature_importances()})\n",
    "        feature_importance.sort_values(by='Importances', inplace=True,ascending = False )\n",
    "        return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training #\n",
    "\n",
    "def get_warm_start_parameter(warm_start_file):\n",
    "    \"\"\"\n",
    "    Checks if the warm start parameter JSON file exists.\n",
    "    If it exists, reads and returns the parameters.\n",
    "    If it does not exist, returns an empty string.\n",
    "\n",
    "    Args:\n",
    "    warm_start_file (str): Path to the warm start parameter JSON file.\n",
    "\n",
    "    Returns:\n",
    "    dict or str: Parameters from the file if it exists, otherwise an empty string.\n",
    "    \"\"\"\n",
    "    if os.path.exists(warm_start_file):\n",
    "        with open(warm_start_file, 'r') as file:\n",
    "            parameters = json.load(file)\n",
    "            return parameters\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def train_profit_loss_binary(data_path, dictionary_path,warm_start_file, model_dir, new_customer):\n",
    "    # Load and label data \n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # create components\n",
    "    hyperparameters = get_warm_start_parameter(warm_start_file)\n",
    "    if hyperparameters != \"\":\n",
    "        warm_starting_param = get_warm_start_parameter(warm_start_file)\n",
    "    else:\n",
    "        warm_starting_param = {\"bagging_fraction\": 0.5492535456145099, \"bagging_freq\": 2, \"feature_fraction\": 0.88, \"lambda_l1\": 0.00011548574578690704, \"lambda_l2\": 1.3199945533897172e-06, \"max_depth\": 12, \"min_child_samples\": 10, \"num_leaves\": 48}\n",
    "    random_state = 456   \n",
    "    fixed_param = {\n",
    "    'objective': 'binary',\n",
    "    'metric':  \"binary_logloss\",\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': random_state,\n",
    "    'verbose': -1,\n",
    "    'feature_pre_filter': False\n",
    "    }\n",
    "\n",
    "    if new_customer:\n",
    "        columns_to_drop = [\"funded_outstanding\",\"priorfundtaphistoryfundedsum\",\"priorfundtaphistorycompletedsum\", \"priorfundtaphistoryduesum\", \"priorfundtaphistorypendingsum\"]\n",
    "        df = df.drop(columns = columns_to_drop, errors = 'ignore')\n",
    "    # full-model \n",
    "    X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight,train_holdout,test_holdout = fundtap_train_test_split(df, \n",
    "                                                                                                              dictionary_path,\n",
    "                                                                                                              random_state=456)\n",
    "    weight = train_instance_weight\n",
    "\n",
    "    def learning_rate_decay_power_0995(current_iter): \n",
    "        base_learning_rate = 0.1 \n",
    "        lr = base_learning_rate * np.power(.995, current_iter) \n",
    "        return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "    def objective(trial):\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 14)\n",
    "        max_num_leaves = (2 ** max_depth) - 1\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train, weight=weight)\n",
    "        param = {\n",
    "             'objective': 'binary',\n",
    "             'metric': \"binary_logloss\",\n",
    "             'verbosity': -1,\n",
    "             'boosting_type': 'gbdt',\n",
    "             'max_depth': max_depth,\n",
    "             'num_leaves': trial.suggest_int('num_leaves', 2, min(128, max_num_leaves)),\n",
    "             'lambda_l1': trial.suggest_float('lambda_l1', 1e-3, 10.0, log=True),\n",
    "             'lambda_l2': trial.suggest_float('lambda_l2', 1e-3, 10.0, log=True),\n",
    "             'feature_fraction': trial.suggest_float('feature_fraction', 0.3, 0.8),\n",
    "             'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "             'bagging_freq': trial.suggest_int('bagging_freq', 1, 5),\n",
    "             'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "             'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-3, 1.0),\n",
    "             'seed': random_state,            \n",
    "         }\n",
    "\n",
    "        lgbcv = lgb.cv(param,\n",
    "                    dtrain,\n",
    "                    nfold=5,\n",
    "                    stratified=True,\n",
    "                    num_boost_round=10000,\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(100),\n",
    "                        lgb.reset_parameter(learning_rate=learning_rate_decay_power_0995)\n",
    "                    ]\n",
    "                    )\n",
    "        print(\"CV Results Keys:\", lgbcv.keys())  # Debugging: Print the keys of the CV results\n",
    "    \n",
    "        score_mean = \"binary_logloss-mean\"\n",
    "        score_stdv = \"binary_logloss-stdv\"\n",
    "\n",
    "        if score_mean in lgbcv and score_stdv in lgbcv:\n",
    "            cv_score = lgbcv[score_mean][-1] + lgbcv[score_stdv][-1]\n",
    "        else:\n",
    "            print(f\"Keys {score_mean} and {score_stdv} not found in CV results.\")\n",
    "            cv_score = float('inf')  # Assign a large value to ensure this trial is not selected\n",
    "\n",
    "        return cv_score\n",
    "       \n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\")  # default TPE sampleR\n",
    "    if warm_starting_param == \"\":\n",
    "        study.enqueue_trial({**fixed_param})\n",
    "    else:\n",
    "        study.enqueue_trial({**fixed_param, **warm_starting_param})\n",
    "    n_trials =35\n",
    "    study.optimize(objective, n_trials=n_trials, gc_after_trial=True, n_jobs = 3)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train, weight=weight)\n",
    "    classifier = lgb.train({**fixed_param, **best_params}, dtrain)\n",
    "    accuracy = accuracy_analysis(\n",
    "        classifier, X_train, X_test, y_train, y_test, test_instance_weight)\n",
    "\n",
    "    # save components\n",
    "    final_dtrain = lgb.Dataset(pd.concat([X_train, X_test]), label=pd.concat([y_train, y_test]), weight=pd.concat([train_instance_weight, test_instance_weight]))\n",
    "    final_clf = lgb.train({**fixed_param, **best_params}, final_dtrain)\n",
    "    \n",
    "    model_dir = Path(model_dir)\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "    if new_customer:\n",
    "        file_prefix = \"new_customer_profitloss\"\n",
    "    else:\n",
    "        file_prefix = \"existing_customer_profitloss\"\n",
    "    joblib.dump(final_clf, Path(model_dir, file_prefix+\"classifier.joblib\"))\n",
    "    accuracy.to_csv(Path(model_dir, file_prefix+\"accuracy.csv\"))\n",
    "    with open(Path(model_dir, file_prefix+\"hyperparamter.json\"), 'w') as fp:\n",
    "        json.dump({**best_params}, fp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean dtype #\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('../data/train.csv', low_memory=False)\n",
    "\n",
    "\n",
    "# Specify the column numbers with mixed data types\n",
    "mixed_type_column_indices = [7, 16]  # Replace with your actual column indices\n",
    "\n",
    "# Convert the column indices to column names\n",
    "mixed_type_columns = df.columns[mixed_type_column_indices]\n",
    "\n",
    "# Function to convert non-int64 values to 0\n",
    "def convert_to_int64(df, columns):\n",
    "    for col in columns:\n",
    "        # Convert column to numeric, setting errors='coerce' will turn non-numeric values to NaN\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        # Fill NaN values with 0 and convert the column to int64\n",
    "        df[col] = df[col].fillna(0).astype('int64')\n",
    "    return df\n",
    "\n",
    "# Convert non-int64 values to 0 for the specified columns\n",
    "df = convert_to_int64(df, mixed_type_columns)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "cleaned_data_path = '../data/train_cleaned.csv'\n",
    "df.to_csv(cleaned_data_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean column names #\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "    df= df.dropna(subset=['fundtap_profit_loss'])\n",
    "    return df\n",
    "\n",
    "# Assuming processed_data is a DataFrame\n",
    "train_data = pd.read_csv('../data/train_cleaned.csv')\n",
    "processed_data = clean_column_names(train_data)\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "processed_data_path = '../data/processed_data.csv'\n",
    "processed_data.to_csv(processed_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train according to the data-dictionary #\n",
    "dictionary_path = \"../data/fundtap-data-dictionary.csv\"\n",
    "warm_start_file = 'path/to/warm_start_parameters.json'\n",
    "model_dir = Path('../model_output')\n",
    "model_dir.mkdir(exist_ok=True, parents=True)\n",
    "new_customer = True\n",
    "\n",
    "# Run the training function\n",
    "train_profit_loss_binary(processed_data_path, dictionary_path, warm_start_file, model_dir, new_customer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= processed_data\n",
    "X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight,train_holdout,test_holdout= fundtap_train_test_split(df, \n",
    "                                                                                                         dictionary_path, \n",
    "                                                                                                         random_state=456)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"Train instance weight shape:\", train_instance_weight)\n",
    "print(\"Test instance weight shape:\", test_instance_weight.shape)\n",
    "print(train_holdout)\n",
    "print(test_holdout)\n",
    "print(len(df.columns))\n",
    "print(df[\"label\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def export_features_to_txt(X_train, X_test, y_train, y_test, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"Features in X_train:\\n\")\n",
    "        f.write(\"\\n\".join(X_train.columns) + \"\\n\\n\")\n",
    "\n",
    "        f.write(\"First 5 rows of X_train:\\n\")\n",
    "        f.write(X_train.head().to_string() + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Features in X_test:\\n\")\n",
    "        f.write(\"\\n\".join(X_test.columns) + \"\\n\\n\")\n",
    "\n",
    "        f.write(\"First 5 rows of X_test:\\n\")\n",
    "        f.write(X_test.head().to_string() + \"\\n\\n\")\n",
    "                      \n",
    "        f.write(\"First 5 values of y_train:\\n\")\n",
    "        f.write(y_train.head().to_string() + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"First 5 values of y_test:\\n\")\n",
    "        f.write(y_test.head().to_string() + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Features of train_instance_weight:\\n\")\n",
    "        f.write(train_instance_weight.to_string() + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Features of test_instance_weight:\\n\")\n",
    "        f.write(test_instance_weight.to_string() + \"\\n\\n\")\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test, train_instance_weight, test_instance_weight are defined\n",
    "export_features_to_txt(X_train, X_test, y_train, y_test, \"../model_output_history/model_features/features_train02.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions updated\n",
    "1. Fix the absence of weighted scores and unexpected high FPR by further cleaned the data(6,7,fundtap_profit_loss)\n",
    "2. Tried to handle warm starting\n",
    "3. Output training data features and instant_weight as txt. \n",
    "4. Added some more parameters but they impacted the model performance (higher FPR and FNR ). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems to be check:\n",
    "1. Warm start file is not created. Where should it build?\n",
    "2. Remain added parameters or remove them to regain the better performance score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
